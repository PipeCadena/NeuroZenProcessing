{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sn\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "#!pip install EDFlib-Python\n",
    "\n",
    "%matplotlib qt\n",
    "%gui qt\n",
    "\n",
    "#str_DataPath = 'C:/Users/Sebastian/Documents/NeuroZenProcessing/Preprocessed/' \n",
    "str_DataPath = \"D:/Preprocessed/\" \n",
    "str_FileName_MF = str_DataPath+'Sujeto35_MF_processed.fif'  \n",
    "str_FileName_R = str_DataPath+'Sujeto35_R_processed.fif'\n",
    "epochs_MF = mne.read_epochs(str_FileName_MF, preload=True)\n",
    "epochs_R = mne.read_epochs(str_FileName_R, preload=True)\n",
    "#num_sujeto = '16'\n",
    "\n",
    "#mne.export.export_raw(\"Sujeto35_MF_processed.edf\", epochs_MF)\n",
    "#epochs_MF.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION MATRIX FOR THE MEAN OF ALL EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_mean_adjacency(epochs):\n",
    "    \n",
    "    m_Data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "    n_epochs, n_channels, n_times = m_Data.shape\n",
    "\n",
    "    adjacency_matrices = np.zeros((n_epochs, n_channels, n_channels))\n",
    "\n",
    "    # Loop through epochs to calculate adjacency matrix for each epoch\n",
    "    for i_epoch in range(n_epochs):\n",
    "        print(f'Processing epoch {i_epoch + 1} of {n_epochs}')\n",
    "        \n",
    "        # Initialize correlation matrix for this epoch\n",
    "        correlation_matrix = np.zeros((n_channels, n_channels))\n",
    "        \n",
    "        # Loop through each pair of channels to calculate Pearson correlation\n",
    "        for i_chan1 in range(n_channels):\n",
    "            for i_chan2 in range(i_chan1, n_channels):\n",
    "                # Get time series data for the two channels in this epoch\n",
    "                time_series_1 = m_Data[i_epoch, i_chan1, :]\n",
    "                time_series_2 = m_Data[i_epoch, i_chan2, :]\n",
    "                \n",
    "                # Calculate Pearson correlation\n",
    "                correlation_value = np.abs(pearsonr(time_series_1, time_series_2)[0])\n",
    "                \n",
    "                # Update correlation matrix (symmetric matrix)\n",
    "                correlation_matrix[i_chan1, i_chan2] = correlation_value\n",
    "                correlation_matrix[i_chan2, i_chan1] = correlation_value\n",
    "        \n",
    "        # Store the correlation matrix as adjacency matrix for this epoch\n",
    "        adjacency_matrices[i_epoch] = correlation_matrix\n",
    "\n",
    "    # Calculate the mean adjacency matrix across all epochs\n",
    "    mean_adjacency_matrix = np.mean(adjacency_matrices, axis=0)\n",
    "    return mean_adjacency_matrix, epochs.ch_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATION MATRIX FOR ALL EPOCHS FOR EACH FREQ BAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bandwise_mean_adjacency(epochs, freq_bands):\n",
    "\n",
    "    ch_names = epochs.ch_names\n",
    "    band_adjacency_matrices = {}\n",
    "\n",
    "    for band, (fmin, fmax) in freq_bands.items():\n",
    "        print(f'Processing {band} band ({fmin}-{fmax} Hz)')\n",
    "\n",
    "        # Filter the data for the specific band\n",
    "        filtered_epochs = epochs.copy().filter(fmin, fmax, fir_design='firwin', verbose=False)\n",
    "        m_Data = filtered_epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "\n",
    "        n_epochs, n_channels, _ = m_Data.shape\n",
    "        adjacency_matrices = np.zeros((n_epochs, n_channels, n_channels))\n",
    "\n",
    "        # Compute correlation for each epoch\n",
    "        for i_epoch in range(n_epochs):\n",
    "            correlation_matrix = np.zeros((n_channels, n_channels))\n",
    "\n",
    "            for i_chan1 in range(n_channels):\n",
    "                for i_chan2 in range(i_chan1, n_channels):\n",
    "                    time_series_1 = m_Data[i_epoch, i_chan1, :]\n",
    "                    time_series_2 = m_Data[i_epoch, i_chan2, :]\n",
    "\n",
    "                    correlation_value = np.abs(pearsonr(time_series_1, time_series_2)[0])\n",
    "\n",
    "                    correlation_matrix[i_chan1, i_chan2] = correlation_value\n",
    "                    correlation_matrix[i_chan2, i_chan1] = correlation_value\n",
    "\n",
    "            adjacency_matrices[i_epoch] = correlation_matrix\n",
    "\n",
    "        # Compute mean adjacency matrix for this band\n",
    "        band_adjacency_matrices[band] = np.mean(adjacency_matrices, axis=0)\n",
    "\n",
    "    return band_adjacency_matrices, ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def normalizeMF(epochs_MF, epochs_R):\n",
    "    \"\"\"\n",
    "    Normalize MF data per channel based on the mean and std of the R data per channel.\n",
    "    \"\"\"\n",
    "    # Get the data from R and MF epochs (shape: n_epochs, n_channels, n_times)\n",
    "    m_Data_MF = epochs_MF.get_data()\n",
    "    m_Data_R = epochs_R.get_data()\n",
    "\n",
    "    # Calculate the mean and std of the R data (across epochs and time) for each channel\n",
    "    mean_R = np.mean(m_Data_R, axis=(0, 2))  # Mean across epochs and time for each channel\n",
    "    std_R = np.std(m_Data_R, axis=(0, 2))    # Std across epochs and time for each channel\n",
    "\n",
    "    # Initialize an array to store normalized MF data\n",
    "    normalized_MF = np.zeros_like(m_Data_MF)\n",
    "    normalized_R = np.zeros_like(m_Data_R)\n",
    "\n",
    "    # Loop through each channel to normalize the data\n",
    "    for i in range(m_Data_MF.shape[1]):  # Loop through channels\n",
    "        # Normalize the MF data for this channel\n",
    "        normalized_MF[:, i, :] = (m_Data_MF[:, i, :] - mean_R[i]) / std_R[i]\n",
    "\n",
    "    for i in range(m_Data_R.shape[1]):  # Loop through channels\n",
    "        # Normalize the MF data for this channel\n",
    "        normalized_R[:, i, :] = (m_Data_R[:, i, :] - mean_R[i]) / std_R[i]\n",
    "\n",
    "    return normalized_MF, normalized_R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREQ BAND MATRIX FOR ALL PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_bandwise_mean_adjacency(epochs, fmin, fmax):\n",
    "    \"\"\"Compute the mean correlation (adjacency) matrix for a given frequency band.\"\"\"\n",
    "    ch_names = epochs.ch_names\n",
    "    \n",
    "    # Filter the epochs to the desired frequency band.\n",
    "    filtered_epochs = epochs.copy().filter(fmin, fmax, fir_design='firwin', verbose=False)\n",
    "    m_Data = filtered_epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "    n_epochs, n_channels, _ = m_Data.shape\n",
    "\n",
    "    # Compute correlation matrices for each epoch\n",
    "    adjacency_matrices = np.zeros((n_epochs, n_channels, n_channels))\n",
    "    for i_epoch in range(n_epochs):\n",
    "        correlation_matrix = np.zeros((n_channels, n_channels))\n",
    "        for i_chan1 in range(n_channels):\n",
    "            for i_chan2 in range(i_chan1, n_channels):\n",
    "                ts1 = m_Data[i_epoch, i_chan1, :]\n",
    "                ts2 = m_Data[i_epoch, i_chan2, :]\n",
    "                correlation_value = np.abs(pearsonr(ts1, ts2)[0])\n",
    "                correlation_matrix[i_chan1, i_chan2] = correlation_value\n",
    "                correlation_matrix[i_chan2, i_chan1] = correlation_value\n",
    "        adjacency_matrices[i_epoch] = correlation_matrix\n",
    "\n",
    "    # Compute the mean correlation matrix over epochs for this band.\n",
    "    return np.mean(adjacency_matrices, axis=0), ch_names\n",
    "\n",
    "\n",
    "# List of patient identifiers (35 subjects)\n",
    "patients = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', \n",
    "            '11', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29', \n",
    "            '30', '31', '32', '33', '34', '36', '37']\n",
    "\n",
    "# Path to the preprocessed data.\n",
    "str_DataPath = 'C:/Users/Sebastian/Documents/NeuroZenProcessing/Preprocessed/'\n",
    "\n",
    "# Define frequency bands\n",
    "FREQ_BANDS = {\n",
    "    \"Delta\": (0.3, 4),\n",
    "    \"Theta\": (4, 8),\n",
    "    \"Alpha\": (8, 12),\n",
    "    \"Beta\": (12, 18),\n",
    "    \"Fast Beta\": (18, 30)\n",
    "}\n",
    "\n",
    "# Folder to save the resulting heatmap plots.\n",
    "save_folder = 'C:/Users/Sebastian/Documents/NeuroZenProcessing/images'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Process one frequency band at a time\n",
    "for band, (fmin, fmax) in FREQ_BANDS.items():\n",
    "    print(f\"\\nProcessing {band} band ({fmin}-{fmax} Hz)\")\n",
    "\n",
    "    all_adjacency_MF = []\n",
    "    all_adjacency_R = []\n",
    "\n",
    "    # Process each patient\n",
    "    for num_sujeto in patients:\n",
    "        print(f\"Processing Sujeto{num_sujeto}\")\n",
    "\n",
    "        str_FileName_MF = os.path.join(str_DataPath, f\"Sujeto{num_sujeto}_MF_processed.fif\")\n",
    "        str_FileName_R = os.path.join(str_DataPath, f\"Sujeto{num_sujeto}_R_processed.fif\")\n",
    "\n",
    "        # Load the epochs\n",
    "        epochs_MF = mne.read_epochs(str_FileName_MF, preload=True)\n",
    "        epochs_R = mne.read_epochs(str_FileName_R, preload=True)\n",
    "\n",
    "        # Normalize the data (using resting data statistics)\n",
    "        normalized_MF, normalized_R = normalizeMF(epochs_MF, epochs_R)\n",
    "\n",
    "        # Convert normalized arrays back into mne.EpochsArray objects\n",
    "        normalized_MF = mne.EpochsArray(normalized_MF, epochs_MF.info)\n",
    "        normalized_R = mne.EpochsArray(normalized_R, epochs_R.info)\n",
    "\n",
    "        # Compute bandwise mean adjacency matrices\n",
    "        adjacencies_MF, tick_labels = calculate_bandwise_mean_adjacency(normalized_MF, fmin, fmax)\n",
    "        adjacencies_R, _ = calculate_bandwise_mean_adjacency(normalized_R, fmin, fmax)\n",
    "\n",
    "        # Store the subject's adjacency matrices\n",
    "        all_adjacency_MF.append(adjacencies_MF)\n",
    "        all_adjacency_R.append(adjacencies_R)\n",
    "\n",
    "    # Compute mean adjacency matrices across all patients for the current band\n",
    "    mean_adjacency_MF = np.mean(all_adjacency_MF, axis=0)\n",
    "    mean_adjacency_R = np.mean(all_adjacency_R, axis=0)\n",
    "    difference_matrix = mean_adjacency_MF - mean_adjacency_R\n",
    "\n",
    "    print(f\"Generating plot for {band} band\")\n",
    "\n",
    "    plt.figure(figsize=(35, 12))\n",
    "\n",
    "    # Plot for Mindfulness condition\n",
    "    plt.subplot(1, 3, 1, aspect='equal')\n",
    "    sn.heatmap(pd.DataFrame(mean_adjacency_MF, columns=tick_labels, index=tick_labels),\n",
    "               xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4})\n",
    "    plt.title(\"Mindfulness\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "    # Plot for Resting condition\n",
    "    plt.subplot(1, 3, 2, aspect='equal')\n",
    "    sn.heatmap(pd.DataFrame(mean_adjacency_R, columns=tick_labels, index=tick_labels),\n",
    "               xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4})\n",
    "    plt.title(\"Resting\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "    # Plot for the Difference (MF - R)\n",
    "    plt.subplot(1, 3, 3, aspect='equal')\n",
    "    sn.heatmap(pd.DataFrame(difference_matrix, columns=tick_labels, index=tick_labels),\n",
    "               xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4}, center=0)\n",
    "    plt.title(\"Difference (MF - R)\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "    plt.suptitle(f\"Correlation Matrices for {band} Band\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.99)\n",
    "\n",
    "    save_path = os.path.join(save_folder, f\"{band}_CorrelationMatrices.png\")\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved plot for {band} band to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATRIX FOR ALL PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Function to calculate mean adjacency matrix for all patients\n",
    "def calculate_mean_adjacency_across_patients(normalized_MF_list, normalized_R_list):\n",
    "    \"\"\"\n",
    "    Calculate the mean adjacency matrix across multiple patients.\n",
    "    \"\"\"\n",
    "    mean_adjacency_MF_list = []\n",
    "    mean_adjacency_R_list = []\n",
    "    num_sujeto = 0\n",
    "    for normalized_MF, normalized_R in zip(normalized_MF_list, normalized_R_list):\n",
    "        adjacency_MF, tick_labels = calculate_mean_adjacency(normalized_MF)\n",
    "        adjacency_R, _ = calculate_mean_adjacency(normalized_R)\n",
    "\n",
    "        np.save(f\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices/Sujeto{patients[num_sujeto]}_MF.npy\", adjacency_MF)\n",
    "        np.save(f\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices/Sujeto{patients[num_sujeto]}_R.npy\", adjacency_R)\n",
    "        print(f\"Saved Sujeto{num_sujeto} correlation matrices\")\n",
    "        mean_adjacency_MF_list.append(adjacency_MF)\n",
    "        mean_adjacency_R_list.append(adjacency_R)\n",
    "        num_sujeto += 1\n",
    "\n",
    "    # Calculate mean adjacency matrices across all patients\n",
    "    mean_adjacency_MF = np.mean(mean_adjacency_MF_list, axis=0)\n",
    "    mean_adjacency_R = np.mean(mean_adjacency_R_list, axis=0)\n",
    "\n",
    "    return mean_adjacency_MF, mean_adjacency_R, tick_labels\n",
    "\n",
    "# Process all patients\n",
    "normalized_MF_list = []\n",
    "normalized_R_list = []\n",
    "\n",
    "patients = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '36', '37'] \n",
    "\n",
    "print(patients)\n",
    "\n",
    "for num_sujeto in patients:\n",
    "    print(f\"Processing Sujeto{num_sujeto} for mean adjacency matrices\")\n",
    "    str_FileName_MF = str_DataPath + f\"Sujeto{num_sujeto}_MF_processed.fif\"\n",
    "    str_FileName_R = str_DataPath + f\"Sujeto{num_sujeto}_R_processed.fif\"\n",
    "\n",
    "    # Load data\n",
    "    normalized_MF = mne.read_epochs(str_FileName_MF, preload=True)\n",
    "    normalized_R = mne.read_epochs(str_FileName_R, preload=True)\n",
    "    \n",
    "    epochs_info = normalized_MF.info\n",
    "    # Normalize data\n",
    "    normalized_MF, normalized_R = normalizeMF(normalized_MF, normalized_R)\n",
    "\n",
    "    # Convert to EpochsArray\n",
    "    normalized_MF = mne.EpochsArray(normalized_MF, epochs_info)\n",
    "    normalized_R = mne.EpochsArray(normalized_R, epochs_info)\n",
    "\n",
    "    # Append to list\n",
    "    normalized_MF_list.append(normalized_MF)\n",
    "    normalized_R_list.append(normalized_R)\n",
    "\n",
    "# Calculate mean adjacency matrices across patients\n",
    "mean_adjacency_MF, mean_adjacency_R, tick_labels = calculate_mean_adjacency_across_patients(\n",
    "    normalized_MF_list, normalized_R_list)\n",
    "\n",
    "# Difference matrix\n",
    "difference_matrix = mean_adjacency_MF - mean_adjacency_R\n",
    "np.save(\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices/ALL_MF_matrix.npy\", mean_adjacency_MF)\n",
    "np.save(\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices/ALL_R_matrix.npy\", mean_adjacency_R)\n",
    "np.save(\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices/ALL_difference_matrix.npy\", difference_matrix)\n",
    "# Plot mean adjacency matrices\n",
    "plt.figure(figsize=(35, 12))\n",
    "\n",
    "plt.subplot(1, 3, 2, aspect='equal')\n",
    "sn.heatmap(pd.DataFrame(mean_adjacency_R, columns=tick_labels, index=tick_labels), \n",
    "           xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4})\n",
    "plt.title(\"Resting\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "plt.subplot(1, 3, 1, aspect='equal')\n",
    "sn.heatmap(pd.DataFrame(mean_adjacency_MF, columns=tick_labels, index=tick_labels), \n",
    "           xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4})\n",
    "plt.title(\"Mindfulness\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "plt.subplot(1, 3, 3, aspect='equal')\n",
    "sn.heatmap(pd.DataFrame(difference_matrix, columns=tick_labels, index=tick_labels), \n",
    "           xticklabels=2, yticklabels=2, cmap='jet', cbar_kws={'shrink': 0.4}, center=0)\n",
    "plt.title(\"Difference (MF - R)\", fontdict={'size': 12, 'weight': 'bold'})\n",
    "\n",
    "plt.suptitle(\"Correlation Matrices for 10 Participants\", \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.99)\n",
    "\n",
    "# Save plot\n",
    "save_folder = 'C:/Users/Sebastian/Documents/NeuroZenProcessing/images'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder, \"CorrelationMatrixAllParticipants.png\")\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved mean adjacency matrix plot to {save_path}\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-louvain\n",
    "#!pip install networkx\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from community import community_louvain\n",
    "import os\n",
    "\n",
    "# Convert adjacency matrices to graphs\n",
    "def create_graph(adjacency_matrix, threshold=0.7, node_labels=None):\n",
    "    \"\"\"\n",
    "    Create an undirected graph from an adjacency matrix, applying a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - adjacency_matrix (np.array): The adjacency matrix.\n",
    "    - threshold (float): Minimum weight for an edge to be included.\n",
    "    - node_labels (list): List of node labels corresponding to the matrix indices.\n",
    "\n",
    "    Returns:\n",
    "    - G (networkx.Graph): The constructed graph.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = [str(i) for i in range(len(adjacency_matrix))]  # Default to numbers if labels are missing\n",
    "\n",
    "    # Ensure node_labels matches adjacency_matrix size\n",
    "    assert len(node_labels) == len(adjacency_matrix), \"Node labels must match matrix size!\"\n",
    "\n",
    "    # Add nodes using real labels\n",
    "    for i, label in enumerate(node_labels):\n",
    "        G.add_node(label)  # Use labels instead of numbers\n",
    "\n",
    "    # Add edges based on threshold\n",
    "    for i in range(len(adjacency_matrix)):\n",
    "        for j in range(i + 1, len(adjacency_matrix)):  # Avoid duplicate edges\n",
    "            if adjacency_matrix[i, j] >= threshold:\n",
    "                G.add_edge(node_labels[i], node_labels[j], weight=adjacency_matrix[i, j])  # Use labels\n",
    "\n",
    "    return G\n",
    "\n",
    "# Compute graph metrics\n",
    "def compute_graph_metrics(G, nrand=50):\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    avg_degree = np.mean([deg for _, deg in G.degree()])\n",
    "    clustering_coeff = nx.average_clustering(G)\n",
    "\n",
    "    # Handle shortest path length only if graph is connected\n",
    "    avg_shortest_path = nx.average_shortest_path_length(G) if nx.is_connected(G) else np.nan  \n",
    "\n",
    "    C_rand_list, L_rand_list = [], []\n",
    "    for _ in range(nrand):\n",
    "        random_graph = nx.gnm_random_graph(num_nodes, num_edges)\n",
    "        \n",
    "        if nx.is_connected(random_graph):  # Only use connected random graphs\n",
    "            C_rand_list.append(nx.average_clustering(random_graph))\n",
    "            L_rand_list.append(nx.average_shortest_path_length(random_graph))\n",
    "\n",
    "    C_rand = np.mean(C_rand_list) if C_rand_list else np.nan\n",
    "    L_rand = np.mean(L_rand_list) if L_rand_list else np.nan\n",
    "\n",
    "    small_worldness = (clustering_coeff / C_rand) / (avg_shortest_path / L_rand) if not np.isnan(C_rand) and not np.isnan(L_rand) and not np.isnan(avg_shortest_path) else np.nan\n",
    "\n",
    "    centrality = np.mean(list(nx.betweenness_centrality(G).values()))\n",
    "    modularity = community_louvain.modularity(community_louvain.best_partition(G), G)\n",
    "\n",
    "    return {\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": num_edges,\n",
    "        \"average_degree\": avg_degree,\n",
    "        \"clustering_coefficient\": clustering_coeff,\n",
    "        \"average_shortest_path\": avg_shortest_path,\n",
    "        \"small_worldness\": small_worldness,\n",
    "        \"betweenness_centrality\": centrality,\n",
    "        \"modularity\": modularity\n",
    "    }\n",
    "\n",
    "\n",
    "# Visualize graph\n",
    "def visualize_graph(G, title, save_path):\n",
    "    \"\"\"\n",
    "    Visualize a network graph.\n",
    "\n",
    "    Parameters:\n",
    "    - G (networkx.Graph): The input graph.\n",
    "    - title (str): Title of the graph.\n",
    "    - save_path (str): Path to save the figure.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)  # Position nodes\n",
    "    nx.draw(G, pos, with_labels=True, node_size=500, node_color='skyblue', edge_color='gray', font_size=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"Graph saved to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "patients = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "            '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '36', '37'] \n",
    "all_metrics = []\n",
    "\n",
    "data_dir = \"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices\"\n",
    "output_csv = \"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/All_Graph_Metrics.csv\"\n",
    "\n",
    "for num_sujeto in patients:\n",
    "    print(f\"Processing Sujeto{num_sujeto}\")\n",
    "    \n",
    "    for state in [\"MF\", \"R\"]:\n",
    "        file_path = os.path.join(data_dir, f\"Sujeto{num_sujeto}_{state}.npy\")\n",
    "        adjacency_matrix = np.load(file_path)\n",
    "        \n",
    "        G = create_graph(adjacency_matrix, threshold=0.7)\n",
    "        metrics = compute_graph_metrics(G, nrand=50)\n",
    "        visualize_graph(G, f\"{state} Graph\", f\"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Graphs/Sujeto{num_sujeto}_{state}_Graph.png\")\n",
    "        metrics[\"Participant\"] = f\"{num_sujeto}_{state}\"\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "df_metrics = pd.DataFrame(all_metrics)\n",
    "df_metrics.to_csv(output_csv, index=False)\n",
    "print(f\"All graph metrics saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load CSV\n",
    "csv_path = \"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/All_Graph_Metrics.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract MF and R data\n",
    "df[\"Participant_ID\"] = df[\"Participant\"].str.split(\"_\").str[0]  # Extract participant number\n",
    "df_MF = df[df[\"Participant\"].str.endswith(\"_MF\")].set_index(\"Participant_ID\")\n",
    "df_R = df[df[\"Participant\"].str.endswith(\"_R\")].set_index(\"Participant_ID\")\n",
    "\n",
    "# Ensure data aligns correctly\n",
    "df_MF = df_MF.sort_index()\n",
    "df_R = df_R.sort_index()\n",
    "\n",
    "# Get metric columns (excluding \"Participant\" and \"Participant_ID\")\n",
    "metric_columns = [col for col in df.columns if col not in [\"Participant\", \"Participant_ID\", \"num_nodes\"]]\n",
    "\n",
    "# Perform paired t-tests\n",
    "t_test_results = {}\n",
    "for metric in metric_columns:\n",
    "    # Drop NaN values from both MF and R before testing\n",
    "    valid_data = df_MF[[metric]].join(df_R[[metric]], lsuffix=\"_MF\", rsuffix=\"_R\").dropna()\n",
    "    \n",
    "    if not valid_data.empty:  # Ensure there's data left to test\n",
    "        t_stat, p_value = ttest_rel(valid_data[f\"{metric}_MF\"], valid_data[f\"{metric}_R\"])\n",
    "        t_test_results[metric] = {\"t-statistic\": t_stat, \"p-value\": p_value}\n",
    "    else:\n",
    "        t_test_results[metric] = {\"t-statistic\": None, \"p-value\": None}  # No valid data\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "df_ttest = pd.DataFrame.from_dict(t_test_results, orient=\"index\")\n",
    "ttest_csv_path = \"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/TTest_Results.csv\"\n",
    "df_ttest.to_csv(ttest_csv_path)\n",
    "\n",
    "print(f\"T-test results saved to {ttest_csv_path}\")\n",
    "print(df_ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = \"C:/Users/Sebastian/Documents/NeuroZenProcessing/Connectivity_Outputs/Matrices\"\n",
    "num_sujeto = '9'\n",
    "state = \"R\"  # or \"R\"\n",
    "file_path = os.path.join(data_dir, f\"Sujeto{num_sujeto}_{state}.npy\")\n",
    "adjacency_matrix = np.load(file_path)\n",
    "\n",
    "\n",
    "def plot_corr_matrix(corr_matrix, labels, title='Reordered Correlation Matrix', cmap='coolwarm'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    cax = ax.matshow(corr_matrix, cmap=cmap, vmin=0, vmax=1)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=90, fontsize=6)\n",
    "    ax.set_yticklabels(labels, fontsize=6)\n",
    "\n",
    "    plt.title(title, y=1.15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "original_labels = ['Fp1', 'Fpz','Fp2','F7','F3','Fz','F4','F8','FC5','FC1','FC2','FC6','T7','C3','Cz','C4','T8','CP5','CP1','CP2',\n",
    "                'CP6','P7','P3','Pz','P4','P8','POz','O1','O2','AF7','AF3','AF4','AF8','F5','F1','F2','F6','FC3','FCz','FC4',\n",
    "              'C5','C1','C2','C6','CP3','CP4','P5','P1','P2','P6','PO5','PO3','PO4','PO6','FT7','FT8','TP7','TP8','PO7','PO8','Oz']\n",
    "ordered_labels = [\n",
    "    'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8',\n",
    "    'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8',\n",
    "    'FT7', 'FT8', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6',\n",
    "    'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
    "    'TP7', 'TP8', 'CP5', 'CP3', 'CP1', 'CP2', 'CP4', 'CP6',\n",
    "    'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8',\n",
    "    'PO7', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'PO8',\n",
    "    'O1', 'Oz', 'O2'\n",
    "]\n",
    "\n",
    "# ---- 4. Reorder the matrix and labels ----\n",
    "label_to_index = {label: i for i, label in enumerate(original_labels)}\n",
    "reorder_idx = [label_to_index[label] for label in ordered_labels]\n",
    "reordered_matrix = adjacency_matrix[np.ix_(reorder_idx, reorder_idx)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# --- Left: Original Matrix ---\n",
    "df_original = pd.DataFrame(adjacency_matrix, index=original_labels, columns=original_labels)\n",
    "sn.heatmap(df_original, cmap='jet', xticklabels=2, yticklabels=2, \n",
    "           cbar_kws={'shrink': 0.5}, ax=axes[0], square=True, vmin=0, vmax=1)\n",
    "axes[0].set_title(\"Original Correlation\", fontsize=12, fontweight='bold')\n",
    "\n",
    "# --- Right: Reordered Matrix ---\n",
    "df_reordered = pd.DataFrame(reordered_matrix, index=ordered_labels, columns=ordered_labels)\n",
    "sn.heatmap(df_reordered, cmap='jet', xticklabels=2, yticklabels=2, \n",
    "           cbar_kws={'shrink': 0.5}, ax=axes[1], square=True, vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Reordered by Brain Region\", fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
